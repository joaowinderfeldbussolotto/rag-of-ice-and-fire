{
    "type": "error",
    "data": "Error Invoking LLM",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n    response = await connection.handle_async_request(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n    raise exc\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 78, in handle_async_request\n    stream = await self._connect(request)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 124, in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_backends\\auto.py\", line 31, in connect_tcp\n    return await self._backend.connect_tcp(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 113, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"C:\\Users\\joaow\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\_base_client.py\", line 1484, in request\n    response = await self._client.send(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 393, in handle_async_request\n    with map_httpcore_exceptions():\n  File \"C:\\Users\\joaow\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 137, in invoke\n    result = await delegate(prompt, **kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\services\\rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\openai\\llm\\openai_text_chat_llm.py\", line 166, in _execute_llm\n    raw_response = await self._client.chat.completions.with_raw_response.create(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\_legacy_response.py\", line 381, in wrapped\n    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\_base_client.py\", line 1742, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\_base_client.py\", line 1516, in request\n    raise APIConnectionError(request=request) from err\nopenai.APIConnectionError: Connection error.\n",
    "source": "Connection error.",
    "details": {
        "prompt": "\nYou are a helpful assistant responsible for generating a comprehensive summary of the data provided below.\nGiven one or more entities, and a list of descriptions, all related to the same entity or group of entities.\nPlease concatenate all of these into a single, comprehensive description. Make sure to include information collected from all the descriptions.\nIf the provided descriptions are contradictory, please resolve the contradictions and provide a single, coherent summary.\nMake sure it is written in third person, and include the entity names so we have the full context.\nLimit the final description length to 500 words.\n\n#######\n-Data-\nEntities: \"WHITE KNIFE\"\nDescription List: [\"A river mentioned by Septon Chayle as where he grew up\", \"A river or region east of which lands will be pledged to Stannis\"]\n#######\nOutput:\n",
        "kwargs": {
            "name": "summarize"
        }
    }
}
{
    "type": "error",
    "data": "Error running pipeline!",
    "stack": "Traceback (most recent call last):\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n    yield\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n    response = await connection.handle_async_request(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n    raise exc\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 78, in handle_async_request\n    stream = await self._connect(request)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 124, in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_backends\\auto.py\", line 31, in connect_tcp\n    return await self._backend.connect_tcp(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 113, in connect_tcp\n    with map_exceptions(exc_map):\n  File \"C:\\Users\\joaow\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ConnectError: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\_base_client.py\", line 1484, in request\n    response = await self._client.send(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 393, in handle_async_request\n    with map_httpcore_exceptions():\n  File \"C:\\Users\\joaow\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ConnectError: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\run\\run_pipeline.py\", line 129, in _run_pipeline\n    result = await workflow_function(config, context)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\workflows\\extract_graph.py\", line 46, in run_workflow\n    entities, relationships, raw_entities, raw_relationships = await extract_graph(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\workflows\\extract_graph.py\", line 116, in extract_graph\n    entities, relationships = await get_summarized_entities_relationships(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\workflows\\extract_graph.py\", line 137, in get_summarized_entities_relationships\n    entity_summaries, relationship_summaries = await summarize_descriptions(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\operations\\summarize_descriptions\\summarize_descriptions.py\", line 106, in summarize_descriptions\n    return await get_summarized(entities_df, relationships_df, semaphore)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\operations\\summarize_descriptions\\summarize_descriptions.py\", line 56, in get_summarized\n    node_results = await asyncio.gather(*node_futures)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\operations\\summarize_descriptions\\summarize_descriptions.py\", line 98, in do_summarize_descriptions\n    results = await strategy_exec(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\operations\\summarize_descriptions\\graph_intelligence_strategy.py\", line 37, in run_graph_intelligence\n    return await run_summarize_descriptions(llm, id, descriptions, callbacks, args)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\operations\\summarize_descriptions\\graph_intelligence_strategy.py\", line 64, in run_summarize_descriptions\n    result = await extractor(id=id, descriptions=descriptions)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\operations\\summarize_descriptions\\description_summary_extractor.py\", line 66, in __call__\n    result = await self._summarize_descriptions(id, descriptions)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\operations\\summarize_descriptions\\description_summary_extractor.py\", line 103, in _summarize_descriptions\n    result = await self._summarize_descriptions_with_llm(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\index\\operations\\summarize_descriptions\\description_summary_extractor.py\", line 122, in _summarize_descriptions_with_llm\n    response = await self._model.achat(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\graphrag\\language_model\\providers\\fnllm\\models.py\", line 82, in achat\n    response = await self.model(prompt, **kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\openai\\llm\\openai_chat_llm.py\", line 94, in __call__\n    return await self._text_chat_llm(prompt, **kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\openai\\services\\openai_tools_parsing.py\", line 130, in __call__\n    return await self._delegate(prompt, **kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\base_llm.py\", line 144, in __call__\n    return await self._decorated_target(prompt, **kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\services\\json.py\", line 78, in invoke\n    return await delegate(prompt, **kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\services\\cached.py\", line 137, in invoke\n    result = await delegate(prompt, **kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\services\\rate_limiter.py\", line 75, in invoke\n    result = await delegate(prompt, **args)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\base\\base_llm.py\", line 126, in _decorator_target\n    output = await self._execute_llm(prompt, kwargs)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\fnllm\\openai\\llm\\openai_text_chat_llm.py\", line 166, in _execute_llm\n    raw_response = await self._client.chat.completions.with_raw_response.create(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\_legacy_response.py\", line 381, in wrapped\n    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\_base_client.py\", line 1742, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"C:\\Users\\joaow\\workspace\\v2-graph-rag\\venv\\lib\\site-packages\\openai\\_base_client.py\", line 1516, in request\n    raise APIConnectionError(request=request) from err\nopenai.APIConnectionError: Connection error.\n",
    "source": "Connection error.",
    "details": null
}
